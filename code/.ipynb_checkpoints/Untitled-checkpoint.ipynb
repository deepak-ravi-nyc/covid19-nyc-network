{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Apr 25 08:28:42 2020\n",
    "\n",
    "@author: deepakravi\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "\n",
    "\n",
    "#%% Load NYC Case Data\n",
    "\n",
    "data_dir = '../../covid-19-nyc-data/'\n",
    "\n",
    "def read_and_date(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'])\n",
    "    return df\n",
    "\n",
    "#age_df = read_and_date(data_dir + 'age.csv')\n",
    "#bed_df = read_and_date(data_dir + 'beds.csv')\n",
    "zc_tests_df = read_and_date(data_dir + 'zcta.csv')\n",
    "#tot_df = read_and_date(data_dir + 'nyc.csv')\n",
    "#hosp_df = read_and_date(data_dir + 'hospitalized.csv')\n",
    "#gender_df = read_and_date(data_dir + 'gender.csv')\n",
    "#borough_df = read_and_date(data_dir + 'borough.csv')\n",
    "#state_df = read_and_date(data_dir + 'state.csv')\n",
    "\n",
    "\n",
    "\n",
    "#%% Load SVI Data\n",
    "\n",
    "data_dir = '../raw_data/'\n",
    "#SVI Index attributes\n",
    "census_df = pd.read_csv(data_dir + 'svi_index_NewYork.csv')\n",
    "#filter out NYC\n",
    "census_df = census_df[census_df['COUNTY'].isin(['Kings','Queens','Bronx','New York','Richmond'])] \n",
    "\n",
    "\n",
    "\n",
    "#%% Load NTA-CTA-ZCTA-ZC Relationships\n",
    "data_dir = '../raw_data/'\n",
    "\n",
    "ct_to_zcta_df = pd.read_csv(data_dir + 'zcta_tract_rel_10.csv')\n",
    "#Select NYC counties\n",
    "ct_to_zcta_df = ct_to_zcta_df[(ct_to_zcta_df['STATE'] == 36) & ct_to_zcta_df['COUNTY'].isin([5,81,61,85,47])]\n",
    "\n",
    "'''\n",
    "nta_to_ct_df = pd.read_excel(data_dir + 'nyc2010census_tabulation_equiv.xlsx', index_col=None, header=3)\n",
    "zcta_to_zipcode = pd.read_excel(data_dir + 'zip_to_zcta_2019.xlsx', index_col=None, header=0)\n",
    "zcta_to_zipcode = zcta_to_zipcode[zcta_to_zipcode['STATE']=='NY']\n",
    "'''\n",
    "\n",
    "# Merge zcta_tests to census data to nta and zcta and census_tracts\n",
    "# Create a backbone, merge the ct/zcta/nta\n",
    "\n",
    "ct_to_zcta_df.rename(columns={'ZCTA5':'zcta'}, inplace=True)\n",
    "ct_to_zcta_df.rename(columns={'TRACT':'census_tract'}, inplace=True)\n",
    "\n",
    "'''\n",
    "nta_to_ct_df.rename(columns={'2010 Census Tract':'census_tract'}, inplace=True)\n",
    "nta_to_ct_df.rename(columns={'Neighborhood Tabulation Area (NTA)':'nta'}, inplace=True)\n",
    "\n",
    "zcta_to_zipcode.rename(columns={'ZIP_CODE':'zip_code'}, inplace=True)\n",
    "zcta_to_zipcode.rename(columns={'ZCTA':'zcta'}, inplace=True)\n",
    "zcta_to_zipcode['zcta'] = zcta_to_zipcode['zcta'].astype('int')\n",
    "\n",
    "backbone_df = nta_to_ct_df.merge(ct_to_zcta_df, on = \"census_tract\", how = 'inner')\n",
    "backbone_df = backbone_df.merge(zcta_to_zipcode, on = \"zcta\", how = 'inner')\n",
    "\n",
    "relationships_df = backbone_df[['zcta','nta','census_tract','zip_code','Borough', 'COUNTY']]\n",
    "'''\n",
    "\n",
    "# Tabling this for now, until as needed \n",
    "# INSTEAD JUST join the census data to the case data\n",
    "\n",
    "master_df = census_df.merge(ct_to_zcta_df, left_on = 'FIPS', right_on = 'GEOID')\n",
    "\n",
    "#Before we merge this we need to find avg rate? base measures, population needs to be joined\n",
    "\n",
    "#Aggregate the Census Tract data by ZCTA and then join columns as needed\n",
    "census_zc_subset = master_df[['zcta', 'POPPT']].groupby('zcta').agg('sum')\n",
    "zcta_tests_df = zc_tests_df.merge(census_zc_subset, on = 'zcta', how = 'left')\n",
    "\n",
    "\n",
    "#%% Load Mobility Data\n",
    "'''\n",
    "turns = pd.read_csv(data_dir +'mta_turnstile_200418.csv')\n",
    "turns['ENTRIES'] = turns['ENTRIES'].astype('int')\n",
    "turns.rename(columns={'EXITS                                                               ':'EXITS'}, inplace=True)\n",
    "turns['EXITS'] = turns['EXITS'].astype('int')\n",
    "                                                      \n",
    "#step 1 subway inflows / outflows from each station\n",
    "turns['ENTRIES'] = turns.groupby(['C/A','STATION','UNIT','SCP'])['ENTRIES'].diff()\n",
    "turns['EXITS'] = turns.groupby(['C/A','STATION','UNIT','SCP'])['EXITS'].diff()\n",
    "turns = turns.groupby(['STATION','DATE', 'LINENAME']).agg('sum')\n",
    "turns = turns.groupby(['STATION', 'LINENAME']).agg('mean').sort_values(by = ['STATION'])\n",
    "\n",
    "\n",
    "#step 2 join stations with neighborhoods by long/lat\n",
    "entrances = pd.read_csv(data_dir +'DOITT_SUBWAY_STATION_01_13SEPT2010.csv')\n",
    "entrances['STATION'] = entrances['NAME'].str.upper()\n",
    "entrances['X'] = entrances['the_geom'].str.split(' ').str[1].str[1:].astype('double')\n",
    "entrances['Y'] = entrances['the_geom'].str.split(' ').str[2].str[:-1].astype('double')\n",
    "#entrances = entrances.groupby('Station Name').first()\n",
    "entrances = entrances[['STATION','X','Y','LINE']].sort_values(by = ['STATION'])\n",
    "'''\n",
    "'''\n",
    "data_dir = '../data/'\n",
    "joined = pd.read_csv(data_dir +'station_locations_joined.csv')\n",
    "geo = pd.read_csv(data_dir +'station_location_final.csv')\n",
    "'''\n",
    "\n",
    "#stations = joined.merge(geo[['STATION','LINE','GEOID']], on = ['STATION','LINE'], how  = 'left')\n",
    "data_dir = '../data/'\n",
    "stations = pd.read_csv(data_dir +'stations_final.csv')\n",
    "#stations.to_csv('../data/stations_final.csv')\n",
    "\n",
    "\n",
    "\n",
    "#entrances.to_csv('../data/station_location.csv')\n",
    "#turns.to_csv('../data/turnstile_counts.csv')\n",
    "\n",
    "#>>>>FAIL\n",
    "#import d6tjoin.top1\n",
    "#import d6tjoin.utils\n",
    "#d6tjoin.utils.PreJoin([entrances,turns],['STATION']).stats_prejoin()\n",
    "#entrances['STATION'] = entrances.index\n",
    "#turns['STATION1'] = turns.index\n",
    "#result = d6tjoin.top1.MergeTop1(entrances,turns,fuzzy_left_on=['STATION1'],fuzzy_right_on=['STATION1']).merge()\n",
    "#<<<<\n",
    "\n",
    "\n",
    "import urllib\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_GEOID(X,Y):\n",
    "    url = ('https://geocoding.geo.census.gov/geocoder/geographies/coordinates?x='+\n",
    "           str(X) + '&y='+ str(Y) + '&benchmark=4&vintage=4&format=json')\n",
    "    response = urllib.request.urlopen(url)\n",
    "    \n",
    "    try:\n",
    "        res_body = response.read()\n",
    "        j = json.loads(res_body.decode(\"utf-8\"))\n",
    "        geoid = int(j['result']['geographies']['Census Tracts'][0]['GEOID'])\n",
    "    except:\n",
    "        geoid = 'ERROR'\n",
    "    \n",
    "    return geoid\n",
    "\n",
    "\n",
    "dicts = []\n",
    "'''\n",
    "for index, row in tqdm(entrances.iterrows()):\n",
    "    \n",
    "    #time.sleep(1)\n",
    "    geoid = get_GEOID(row['X'], row['Y'])\n",
    "    di = {'X':row['X'], 'Y':row['Y'], 'GEOID':geoid}\n",
    "    dicts.append(di)\n",
    "    \n",
    "geoids = pd.DataFrame(dicts)\n",
    "\n",
    "entrances = entrances.merge(geoids, on = ['X', 'Y'])\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#%% Create Master DF\n",
    "#Aggregate the Census Tract data by ZCTA and then join columns as needed\n",
    "census_zc_subset = master_df[['zcta', 'POPPT']].groupby('zcta').agg('sum')\n",
    "zcta_tests_df = zc_tests_df.merge(census_zc_subset, on = 'zcta', how = 'left')\n",
    "zcta_tests_df = zcta_tests_df[zcta_tests_df['zcta'] < 12000] #filter out NaN data\n",
    "\n",
    "\n",
    "zcta_tests_df['percent_positive'] = zcta_tests_df['positive']/zcta_tests_df['total']*100\n",
    "zcta_tests_df['percent_tested'] = zcta_tests_df['total']/zcta_tests_df['POPPT']*100\n",
    "\n",
    "zcta_tests_df['new_positive'] = zcta_tests_df.groupby('zcta')['positive'].diff()\n",
    "zcta_tests_df['new_test'] = zcta_tests_df.groupby('zcta')['total'].diff()\n",
    "\n",
    "zcta_tests_df['percent_new_positive'] = zcta_tests_df['new_positive']/zcta_tests_df['new_test']*100\n",
    "zcta_tests_df['percent_new_tested'] = zcta_tests_df['new_test']/zcta_tests_df['POPPT']*100\n",
    "\n",
    "tests_grouped = zcta_tests_df.groupby('zcta').agg({'positive':'first', 'percent_new_positive':'mean', 'new_positive':'mean'})\n",
    "\n",
    "\n",
    "#organize_census tracts by ascending order, give index\n",
    "master_df_2 = master_df[['zcta', 'census_tract', 'GEOID', 'E_TOTPOP', 'LOCATION']] \n",
    "\n",
    "#left join zcta\n",
    "temp_master = master_df_2[['GEOID','zcta']].merge(tests_grouped, how = 'left', on = 'zcta')\n",
    "\n",
    "#cases data groupy zcta total / count of instances #divide out the multiple cts per zctasmaster\n",
    "temp_master = temp_master.groupby('zcta').agg({'positive':'sum', 'GEOID':'count', 'percent_new_positive':'mean', 'new_positive':'sum'}) \n",
    "temp_master.rename(columns={'GEOID':'GEOID_count'}, inplace=True)\n",
    "#sum / count = individual ct values\n",
    "temp_master['ct_first_positives'] = temp_master['positive']/temp_master['GEOID_count']\n",
    "temp_master['ct_avg_new_positives'] = temp_master['new_positive']/temp_master['GEOID_count']\n",
    "temp_master['ct_avg_new_positives_percent'] = temp_master['percent_new_positive']\n",
    "\n",
    "#rejoin left with master_df\n",
    "temp_master = master_df_2[['GEOID','zcta']].merge(temp_master, how = 'left', on = 'zcta')\n",
    "\n",
    "#group by ct for sum rates\n",
    "temp_master = temp_master.groupby('GEOID').agg({'ct_avg_new_positives':'mean',\n",
    "                                                'ct_avg_new_positives_percent':'mean',\n",
    "                                                'ct_first_positives':'sum'})\n",
    "\n",
    "\n",
    "#Aggregate the Census Tract data by ZCTA and then join columns as needed\n",
    "census_zc_subset = master_df[['zcta', 'POPPT']].groupby('zcta').agg('sum')\n",
    "zcta_tests_df = zc_tests_df.merge(census_zc_subset, on = 'zcta', how = 'left')\n",
    "zcta_tests_df = zcta_tests_df[zcta_tests_df['zcta'] < 12000] #filter out NaN data\n",
    "\n",
    "\n",
    "zcta_tests_df['percent_positive'] = zcta_tests_df['positive']/zcta_tests_df['total']*100\n",
    "zcta_tests_df['percent_tested'] = zcta_tests_df['total']/zcta_tests_df['POPPT']*100\n",
    "\n",
    "zcta_tests_df['new_positive'] = zcta_tests_df.groupby('zcta')['positive'].diff()\n",
    "zcta_tests_df['new_test'] = zcta_tests_df.groupby('zcta')['total'].diff()\n",
    "\n",
    "zcta_tests_df['percent_new_positive'] = zcta_tests_df['new_positive']/zcta_tests_df['new_test']*100\n",
    "zcta_tests_df['percent_new_tested'] = zcta_tests_df['new_test']/zcta_tests_df['POPPT']*100\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>zcta</th>\n",
       "      <th>positive</th>\n",
       "      <th>total</th>\n",
       "      <th>datetime</th>\n",
       "      <th>POPPT</th>\n",
       "      <th>percent_positive</th>\n",
       "      <th>percent_tested</th>\n",
       "      <th>new_positive</th>\n",
       "      <th>new_test</th>\n",
       "      <th>percent_new_positive</th>\n",
       "      <th>percent_new_tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-31T04:00:00Z</td>\n",
       "      <td>10001.0</td>\n",
       "      <td>113</td>\n",
       "      <td>265</td>\n",
       "      <td>2020-03-31 04:00:00+00:00</td>\n",
       "      <td>21102.0</td>\n",
       "      <td>42.641509</td>\n",
       "      <td>1.255805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-31T04:00:00Z</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>250</td>\n",
       "      <td>542</td>\n",
       "      <td>2020-03-31 04:00:00+00:00</td>\n",
       "      <td>81410.0</td>\n",
       "      <td>46.125461</td>\n",
       "      <td>0.665766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-31T04:00:00Z</td>\n",
       "      <td>10003.0</td>\n",
       "      <td>161</td>\n",
       "      <td>379</td>\n",
       "      <td>2020-03-31 04:00:00+00:00</td>\n",
       "      <td>56024.0</td>\n",
       "      <td>42.480211</td>\n",
       "      <td>0.676496</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-31T04:00:00Z</td>\n",
       "      <td>10004.0</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>2020-03-31 04:00:00+00:00</td>\n",
       "      <td>3089.0</td>\n",
       "      <td>42.105263</td>\n",
       "      <td>1.230172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-03-31T04:00:00Z</td>\n",
       "      <td>10005.0</td>\n",
       "      <td>25</td>\n",
       "      <td>81</td>\n",
       "      <td>2020-03-31 04:00:00+00:00</td>\n",
       "      <td>7135.0</td>\n",
       "      <td>30.864198</td>\n",
       "      <td>1.135249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp     zcta  positive  total                  datetime  \\\n",
       "1  2020-03-31T04:00:00Z  10001.0       113    265 2020-03-31 04:00:00+00:00   \n",
       "2  2020-03-31T04:00:00Z  10002.0       250    542 2020-03-31 04:00:00+00:00   \n",
       "3  2020-03-31T04:00:00Z  10003.0       161    379 2020-03-31 04:00:00+00:00   \n",
       "4  2020-03-31T04:00:00Z  10004.0        16     38 2020-03-31 04:00:00+00:00   \n",
       "5  2020-03-31T04:00:00Z  10005.0        25     81 2020-03-31 04:00:00+00:00   \n",
       "\n",
       "     POPPT  percent_positive  percent_tested  new_positive  new_test  \\\n",
       "1  21102.0         42.641509        1.255805           NaN       NaN   \n",
       "2  81410.0         46.125461        0.665766           NaN       NaN   \n",
       "3  56024.0         42.480211        0.676496           NaN       NaN   \n",
       "4   3089.0         42.105263        1.230172           NaN       NaN   \n",
       "5   7135.0         30.864198        1.135249           NaN       NaN   \n",
       "\n",
       "   percent_new_positive  percent_new_tested  \n",
       "1                   NaN                 NaN  \n",
       "2                   NaN                 NaN  \n",
       "3                   NaN                 NaN  \n",
       "4                   NaN                 NaN  \n",
       "5                   NaN                 NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcta_tests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_tests_df = zcta_tests_df.merge(master_df[['GEOID','zcta']], how = 'left', on = 'zcta')\n",
    "zcta_tests_df.to_pickle('tests.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dicts = []\n",
    "\n",
    "for date in zcta_tests_df['datetime']:\n",
    "    zcta_tests_df[zcta_tests_df['datetime'] > date]\n",
    "\n",
    "    #tests_grouped = zcta_tests_df.groupby('zcta').agg({'positive':'first', 'percent_new_positive':'mean', 'new_positive':'mean'})\n",
    "\n",
    "    #organize_census tracts by ascending order, give index\n",
    "    master_df_2 = master_df[['zcta', 'census_tract', 'GEOID', 'E_TOTPOP', 'LOCATION']] \n",
    "\n",
    "    #left join zcta\n",
    "    temp_master = master_df_2[['GEOID','zcta']].merge(tests_grouped, how = 'left', on = 'zcta')\n",
    "\n",
    "    #cases data groupy zcta total / count of instances #divide out the multiple cts per zctasmaster\n",
    "    temp_master = temp_master.groupby('zcta').agg({'positive':'sum', 'GEOID':'count', 'percent_new_positive':'mean', 'new_positive':'sum'}) \n",
    "    temp_master.rename(columns={'GEOID':'GEOID_count'}, inplace=True)\n",
    "    #sum / count = individual ct values\n",
    "    temp_master['ct_first_positives'] = temp_master['positive']/temp_master['GEOID_count']\n",
    "    temp_master['ct_avg_new_positives'] = temp_master['new_positive']/temp_master['GEOID_count']\n",
    "    temp_master['ct_avg_new_positives_percent'] = temp_master['percent_new_positive']\n",
    "\n",
    "    data_one_year = dict(\n",
    "                        type='choropleth',\n",
    "                        locations = df_sected_crime['State_code'],\n",
    "                        z=df_sected_crime['Murder_per100000'].astype(float),\n",
    "                        locationmode='USA-states',\n",
    "                        colorscale = scl,\n",
    "                        text = df_sected_crime['text'],\n",
    "                        )\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
